// Code generated by software.amazon.smithy.rust.codegen.smithy-rs. DO NOT EDIT.
impl super::Client {
    /// Constructs a fluent builder for the [`GetInferenceProfile`](crate::operation::get_inference_profile::builders::GetInferenceProfileFluentBuilder) operation.
    ///
    /// - The fluent builder is configurable:
    ///   - [`inference_profile_identifier(impl Into<String>)`](crate::operation::get_inference_profile::builders::GetInferenceProfileFluentBuilder::inference_profile_identifier) / [`set_inference_profile_identifier(Option<String>)`](crate::operation::get_inference_profile::builders::GetInferenceProfileFluentBuilder::set_inference_profile_identifier):<br>required: **true**<br><p>The ID or Amazon Resource Name (ARN) of the inference profile.</p><br>
    /// - On success, responds with [`GetInferenceProfileOutput`](crate::operation::get_inference_profile::GetInferenceProfileOutput) with field(s):
    ///   - [`inference_profile_name(String)`](crate::operation::get_inference_profile::GetInferenceProfileOutput::inference_profile_name): <p>The name of the inference profile.</p>
    ///   - [`description(Option<String>)`](crate::operation::get_inference_profile::GetInferenceProfileOutput::description): <p>The description of the inference profile.</p>
    ///   - [`created_at(Option<DateTime>)`](crate::operation::get_inference_profile::GetInferenceProfileOutput::created_at): <p>The time at which the inference profile was created.</p>
    ///   - [`updated_at(Option<DateTime>)`](crate::operation::get_inference_profile::GetInferenceProfileOutput::updated_at): <p>The time at which the inference profile was last updated.</p>
    ///   - [`inference_profile_arn(String)`](crate::operation::get_inference_profile::GetInferenceProfileOutput::inference_profile_arn): <p>The Amazon Resource Name (ARN) of the inference profile.</p>
    ///   - [`models(Vec::<InferenceProfileModel>)`](crate::operation::get_inference_profile::GetInferenceProfileOutput::models): <p>A list of information about each model in the inference profile.</p>
    ///   - [`inference_profile_id(String)`](crate::operation::get_inference_profile::GetInferenceProfileOutput::inference_profile_id): <p>The unique identifier of the inference profile.</p>
    ///   - [`status(InferenceProfileStatus)`](crate::operation::get_inference_profile::GetInferenceProfileOutput::status): <p>The status of the inference profile. <code>ACTIVE</code> means that the inference profile is ready to be used.</p>
    ///   - [`r#type(InferenceProfileType)`](crate::operation::get_inference_profile::GetInferenceProfileOutput::type): <p>The type of the inference profile. The following types are possible:</p> <ul>  <li>   <p><code>SYSTEM_DEFINED</code> – The inference profile is defined by Amazon Bedrock. You can route inference requests across regions with these inference profiles.</p></li>  <li>   <p><code>APPLICATION</code> – The inference profile was created by a user. This type of inference profile can track metrics and costs when invoking the model in it. The inference profile may route requests to one or multiple regions.</p></li> </ul>
    /// - On failure, responds with [`SdkError<GetInferenceProfileError>`](crate::operation::get_inference_profile::GetInferenceProfileError)
    pub fn get_inference_profile(&self) -> crate::operation::get_inference_profile::builders::GetInferenceProfileFluentBuilder {
        crate::operation::get_inference_profile::builders::GetInferenceProfileFluentBuilder::new(self.handle.clone())
    }
}
